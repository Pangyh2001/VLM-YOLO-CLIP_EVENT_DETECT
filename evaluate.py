#!/usr/bin/env python3
import os
import random
import yaml
import numpy as np
from pathlib import Path
from tqdm import tqdm
import torch.multiprocessing as mp
import math
import sys

# --- é…ç½®éƒ¨åˆ† ---
DATASET_ROOT = "/data2/pyh/video_stream_event_detection/zhongjifangan/dataset/easy_data"
CONFIG_PATH = "config.yaml"
SAMPLE_SIZE = 500
OUTPUT_DIR = "./evaluation_results"
GPU_IDS = [4, 6, 7]  # ä½¿ç”¨çš„GPUç¼–å·

GT_MAPPING = {
    "Enter": "Entering Exiting",
    "Exit": "Entering Exiting",
    "petting_cat": "Petting Cat",
    "dining": "Dining",
    "eating_cake": "Eating Cake",
    "carrying_baby": "Carrying Baby",
    "crawling_baby": "Baby Crawling",
    "Hand_clap": "Clapping",
    "Hand_wave": "Waving",
    "petting_animal_(not_cat)": "Petting Animal",
    "walking_the_dog": "Walking Dog"
}

def load_and_patch_config(config_path):
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    if 'output' in config:
        config['output']['save_json'] = True 
        config['output']['save_event_images'] = False 
        config['output']['detailed_logging'] = False  
    return config

def get_test_dataset(root_dir, sample_size):
    all_videos = []
    root = Path(root_dir)
    for folder in root.iterdir():
        if folder.is_dir() and folder.name in GT_MAPPING:
            gt = GT_MAPPING[folder.name]
            videos = list(folder.glob("*.mp4")) + list(folder.glob("*.avi"))
            for v in videos:
                all_videos.append({"path": str(v), "folder": folder.name, "gt_event": gt})
    
    if len(all_videos) > sample_size:
        return random.sample(all_videos, sample_size)
    return all_videos

# --- æ ¸å¿ƒå·¥ä½œå‡½æ•° ---
def worker_process(gpu_id, video_subset, config, output_queue):
    """
    æ¯ä¸ªGPUä¸Šè¿è¡Œçš„å·¥ä½œè¿›ç¨‹
    """
    try:
        # 1. å…ˆè®¾ç½®æ˜¾å¡å¯è§æ€§ï¼Œå†å¯¼å…¥ torch
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
        
        # å»¶è¿Ÿå¯¼å…¥ï¼Œé˜²æ­¢ä¸»è¿›ç¨‹åˆå§‹åŒ–CUDA
        from event_detector import EventDetector
        from video_source import VideoSource
        from event_processor import EventTracker # éœ€è¦å¯¼å…¥è¿™ä¸ªæ¥é‡ç½®çŠ¶æ€
        import torch

        print(f"ğŸš€ GPU {gpu_id}: Initialized. Processing {len(video_subset)} videos")
        
        # 2. ã€å…³é”®ä¿®æ”¹ã€‘åœ¨å¾ªç¯å¤–åªåˆå§‹åŒ–ä¸€æ¬¡æ£€æµ‹å™¨
        # è¿™æ ·æ¨¡å‹åªåŠ è½½ä¸€æ¬¡ï¼Œæ˜¾å­˜å ç”¨ç¨³å®šåœ¨ 15GB å·¦å³
        detector = EventDetector(config)
        
        # é¢„è®¾ç½® YOLO ç±»åˆ«
        all_entities = set()
        for event in config['events']:
            all_entities.update(event['entities'])
        detector.model_manager.set_yolo_classes(list(all_entities))
        
        local_metrics = {"total": 0, "correct": 0, "miss": 0, "false_alarm": 0}
        local_results = []
        
        # å®šä¹‰å†…éƒ¨å¤„ç†å‡½æ•°
        def process_video_stream(det, v_path):
            v_source = VideoSource.from_file(v_path)
            detected = set()
            try:
                for fd in v_source:
                    det.process_frame(fd['frame'], fd['frame_time'])
                
                # æ”¶é›† ongoing å’Œ completed çš„äº‹ä»¶
                for res in det.detection_results:
                    if res.get('status') in ['ongoing', 'completed']:
                        detected.add(res['event_name'])
            finally:
                v_source.close()
            return detected

        # å®šä¹‰é‡ç½®çŠ¶æ€å‡½æ•°
        def reset_detector_state(det):
            # æ¸…ç©ºç»“æœåˆ—è¡¨
            det.detection_results = []
            det.frame_count = 0
            det.processed_frame_count = 0
            det.current_fps = det.base_fps
            det.no_detection_count = 0
            
            # é‡ç½®äº‹ä»¶è¿½è¸ªå™¨ (åˆ›å»ºä¸€ä¸ªæ–°çš„ Tracker å®ä¾‹æœ€å¹²å‡€)
            det.event_tracker = EventTracker(det.config)
            for evt in det.config['events']:
                det.event_tracker.init_event(evt['name'])

        # 3. å¾ªç¯å¤„ç†è§†é¢‘
        iterator = tqdm(video_subset, desc=f"GPU {gpu_id}", position=gpu_id) if len(video_subset) > 0 else video_subset
        
        for video_info in iterator:
            local_metrics["total"] += 1
            video_path = video_info['path']
            video_name = Path(video_path).stem 
            
            # A. é‡ç½®æ£€æµ‹å™¨çŠ¶æ€ (å¤ç”¨å®ä¾‹)
            reset_detector_state(detector)
            
            # B. è¿è¡Œæ£€æµ‹
            detected_set = process_video_stream(detector, video_path)
            
            # C. ç­‰å¾… VLM å¼‚æ­¥ä»»åŠ¡å…¨éƒ¨å®Œæˆ (å…³é”®!)
            # å¿…é¡»ç­‰å¾…ä¸Šä¸€æ¡è§†é¢‘çš„ VLM åˆ¤å†³åšå®Œï¼Œé˜²æ­¢ä¸²å°
            detector.vlm_pool.task_queue.join() 
            
            # è¡¥å……æ£€æŸ¥ï¼šå¦‚æœæœ‰åˆšæ‰ VLM åˆšç¡®è®¤çš„äº‹ä»¶ï¼ŒåŠ è¿›æ¥
            for res in detector.detection_results:
                if res.get('status') in ['ongoing', 'completed']:
                    detected_set.add(res['event_name'])

            # D. ä¿å­˜ç»“æœ
            json_filename = f"{video_name}_result.json"
            save_path = os.path.join(OUTPUT_DIR, json_filename)
            detector.save_results(output_path=save_path)
            
            # E. ã€å…³é”®ã€‘ä¸è¦è°ƒç”¨ detector.stop()ï¼Œå¦åˆ™çº¿ç¨‹æ± ä¼šæ­»æ‰
            # æˆ‘ä»¬åªåœ¨æ‰€æœ‰è§†é¢‘è·‘å®Œå stop ä¸€æ¬¡
            
            # F. ç»Ÿè®¡
            gt_event = video_info['gt_event']
            is_correct = False
            status = ""
            
            if len(detected_set) == 0:
                local_metrics["miss"] += 1
                status = "â­• Miss"
            elif gt_event in detected_set:
                local_metrics["correct"] += 1
                is_correct = True
                status = "âœ…"
            else:
                local_metrics["false_alarm"] += 1
                status = "âŒ False"
                
            if not is_correct:
                local_results.append(f"{status} | GT: {gt_event:<15} | Det: {list(detected_set)} | {video_name}")
        
        # 4. æ‰€æœ‰è§†é¢‘è·‘å®Œï¼Œå½»åº•é‡Šæ”¾èµ„æº
        detector.stop(should_save=False)
        
        # å‘å›ç»“æœ
        output_queue.put((gpu_id, local_metrics, local_results))
        
    except Exception as e:
        print(f"âŒ GPU {gpu_id} Error: {e}")
        import traceback
        traceback.print_exc()
        # å‘é€ç©ºç»“æœé˜²æ­¢ä¸»è¿›ç¨‹æ­»é”
        output_queue.put((gpu_id, {"total":0,"correct":0,"miss":0,"false_alarm":0}, []))

def main():
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹å¼
    try:
        mp.set_start_method('spawn', force=True)
    except RuntimeError:
        pass
    
    # æ¸…ç†ç¯å¢ƒå˜é‡
    if "CUDA_VISIBLE_DEVICES" in os.environ:
        del os.environ["CUDA_VISIBLE_DEVICES"]

    config = load_and_patch_config(CONFIG_PATH)
    test_videos = get_test_dataset(DATASET_ROOT, SAMPLE_SIZE)
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # å°†è§†é¢‘åˆ†é…åˆ°ä¸åŒGPU
    num_gpus = len(GPU_IDS)
    if num_gpus == 0: return

    # å‡åŒ€åˆ‡åˆ†
    chunk_size = math.ceil(len(test_videos) / num_gpus)
    video_subsets = [test_videos[i:i + chunk_size] for i in range(0, len(test_videos), chunk_size)]
    
    print(f"ğŸ“Š Distribution:")
    for i in range(len(video_subsets)):
        print(f"  GPU {GPU_IDS[i]}: {len(video_subsets[i])} videos")
    
    # åˆ›å»ºè¿›ç¨‹å’Œé˜Ÿåˆ—
    output_queue = mp.Queue()
    processes = []
    
    for i in range(len(video_subsets)):
        gpu_id = GPU_IDS[i]
        p = mp.Process(target=worker_process, 
                       args=(gpu_id, video_subsets[i], config, output_queue))
        p.start()
        processes.append(p)
    
    # æ”¶é›†ç»“æœ
    total_metrics = {"total": 0, "correct": 0, "miss": 0, "false_alarm": 0}
    all_results_log = []
    finished_count = 0
    
    while finished_count < len(processes):
        gpu_id, metrics, results = output_queue.get()
        print(f"\nğŸ“Š GPU {gpu_id} finished.")
        
        for key in total_metrics:
            total_metrics[key] += metrics[key]
        all_results_log.extend(results)
        finished_count += 1
    
    for p in processes:
        p.join()
    
    # æ‰“å°æ€»ä½“æŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ“Š Overall Evaluation Report")
    print("="*60)
    total = total_metrics['total']
    if total > 0:
        print(f"Total: {total}")
        print(f"Correct: {total_metrics['correct']} ({total_metrics['correct']/total*100:.2f}%)")
        print(f"Miss: {total_metrics['miss']} ({total_metrics['miss']/total*100:.2f}%)")
        print(f"False: {total_metrics['false_alarm']} ({total_metrics['false_alarm']/total*100:.2f}%)")
    else:
        print("No videos processed.")
    print("-" * 60)
    
    for log in all_results_log:
        print(log)

if __name__ == "__main__":
    main()