import os
import json
import cv2
import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path
import csv


class DetailedLogger:
    """è¯¦ç»†è®°å½•æ¯ä¸ªæ¨¡å—çš„å¤„ç†ç»“æœ"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.output_config = config['output']
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯¦ç»†è®°å½•
        self.enabled = self.output_config.get('detailed_logging', False)
        
        if not self.enabled:
            print("â„¹ï¸  Detailed logging is disabled")
            return
        
        # åˆ›å»ºæ—¶é—´æˆ³æ–‡ä»¶å¤¹
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_dir = self.output_config.get('output_base_dir', './output')
        self.session_dir = os.path.join(base_dir, timestamp)
        
        # åˆ›å»ºå­ç›®å½•
        self.yolo_dir = os.path.join(self.session_dir, '1_yolo_detections')
        self.clip_dir = os.path.join(self.session_dir, '2_clip_scores')
        self.vlm_dir = os.path.join(self.session_dir, '3_vlm_verifications')
        self.summary_dir = os.path.join(self.session_dir, 'summary')
        
        for dir_path in [self.yolo_dir, self.clip_dir, self.vlm_dir, self.summary_dir]:
            os.makedirs(dir_path, exist_ok=True)
        
        # é‡‡æ ·ç‡
        self.yolo_sample_rate = self.output_config.get('yolo_sample_rate', 30)
        self.clip_sample_rate = self.output_config.get('clip_sample_rate', 10)
        
        # è®°å½•å¼€å…³
        self.save_yolo = self.output_config.get('save_yolo_detections', True)
        self.save_clip = self.output_config.get('save_clip_scores', True)
        self.save_vlm = self.output_config.get('save_vlm_results', True)
        
        # æ•°æ®è®°å½•
        self.clip_scores_data = []
        self.yolo_frame_count = 0
        self.clip_frame_count = 0
        
        # åˆ›å»ºCSVæ–‡ä»¶
        if self.save_clip:
            self.clip_csv_path = os.path.join(self.clip_dir, 'clip_scores.csv')
            self.clip_csv_file = open(self.clip_csv_path, 'w', newline='', encoding='utf-8')
            self.clip_csv_writer = None  # å°†åœ¨ç¬¬ä¸€æ¬¡å†™å…¥æ—¶åˆå§‹åŒ–
        
        print(f"ğŸ“ Detailed logging enabled: {self.session_dir}")
    
    def log_yolo_detection(self, frame: np.ndarray, detections: List[Dict], 
                          frame_time: float, frame_idx: int):
        """è®°å½•YOLOæ£€æµ‹ç»“æœ"""
        if not self.enabled or not self.save_yolo:
            return
        
        self.yolo_frame_count += 1
        
        # é‡‡æ ·ä¿å­˜
        if self.yolo_frame_count % self.yolo_sample_rate != 0:
            return
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        vis_frame = frame.copy()
        
        for det in detections:
            x1, y1, x2, y2 = map(int, det['bbox'])
            label = f"{det['class']} {det['conf']:.2f}"
            if det['id'] != -1:
                label += f" ID:{det['id']}"
            
            # ç»˜åˆ¶æ¡†
            color = self._get_class_color(det['class'])
            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(vis_frame, (x1, y1-text_h-10), (x1+text_w, y1), color, -1)
            cv2.putText(vis_frame, label, (x1, y1-5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # æ·»åŠ ä¿¡æ¯æ–‡æœ¬
        info_text = f"Frame: {frame_idx} | Time: {frame_time:.2f}s | Detections: {len(detections)}"
        cv2.putText(vis_frame, info_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        
        # ä¿å­˜å›¾åƒ
        filename = f"frame_{frame_idx:06d}_t{frame_time:.2f}s.jpg"
        filepath = os.path.join(self.yolo_dir, filename)
        cv2.imwrite(filepath, vis_frame)
        
        # ä¿å­˜æ£€æµ‹æ•°æ®
        json_filename = f"frame_{frame_idx:06d}_detections.json"
        json_filepath = os.path.join(self.yolo_dir, json_filename)
        
        data = {
            'frame_idx': frame_idx,
            'frame_time': frame_time,
            'detections': detections
        }
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def log_clip_scores(self, frame: np.ndarray, event_scores: Dict[str, float],
                       frame_time: float, frame_idx: int, detections: List[Dict]):
        """è®°å½•CLIPç›¸ä¼¼åº¦å¾—åˆ†"""
        if not self.enabled or not self.save_clip:
            return
        
        self.clip_frame_count += 1
        
        # è®°å½•åˆ°CSVï¼ˆæ‰€æœ‰å¸§ï¼‰
        row_data = {
            'frame_idx': frame_idx,
            'frame_time': frame_time,
            'num_detections': len(detections)
        }
        row_data.update(event_scores)
        
        # åˆå§‹åŒ–CSV writerï¼ˆç¬¬ä¸€æ¬¡å†™å…¥æ—¶ï¼‰
        if self.clip_csv_writer is None:
            fieldnames = ['frame_idx', 'frame_time', 'num_detections'] + list(event_scores.keys())
            self.clip_csv_writer = csv.DictWriter(self.clip_csv_file, fieldnames=fieldnames)
            self.clip_csv_writer.writeheader()
        
        self.clip_csv_writer.writerow(row_data)
        self.clip_scores_data.append(row_data)
        
        # é‡‡æ ·ä¿å­˜å¯è§†åŒ–å›¾åƒ
        if self.clip_frame_count % self.clip_sample_rate != 0:
            return
        
        # åˆ›å»ºå¯è§†åŒ–
        vis_frame = frame.copy()
        h, w = vis_frame.shape[:2]
        
        # åˆ›å»ºå¾—åˆ†é¢æ¿
        panel_height = 200
        panel = np.zeros((panel_height, w, 3), dtype=np.uint8)
        panel[:] = (40, 40, 40)
        
        # ç»˜åˆ¶æ ‡é¢˜
        cv2.putText(panel, f"Frame {frame_idx} | Time: {frame_time:.2f}s", 
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ç»˜åˆ¶å¾—åˆ†æ¡å½¢å›¾
        if event_scores:
            sorted_events = sorted(event_scores.items(), key=lambda x: x[1], reverse=True)
            max_score = max(event_scores.values()) if event_scores else 1.0
            min_score = min(event_scores.values()) if event_scores else 0.0
            
            bar_width = w - 40
            bar_height = 20
            y_start = 60
            
            for i, (event_name, score) in enumerate(sorted_events):
                y = y_start + i * (bar_height + 10)
                
                # ç»˜åˆ¶å¾—åˆ†æ¡
                if max_score > min_score:
                    normalized_score = (score - min_score) / (max_score - min_score)
                else:
                    normalized_score = 0.5
                
                bar_len = int(bar_width * normalized_score)
                color = (0, 255, 0) if i == 0 else (100, 100, 255)  # æœ€é«˜åˆ†ç»¿è‰²
                
                cv2.rectangle(panel, (20, y), (20 + bar_len, y + bar_height), color, -1)
                cv2.rectangle(panel, (20, y), (20 + bar_width, y + bar_height), (150, 150, 150), 1)
                
                # ç»˜åˆ¶æ–‡æœ¬
                text = f"{event_name}: {score:.3f}"
                cv2.putText(panel, text, (25, y + 15), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # æ‹¼æ¥å›¾åƒå’Œé¢æ¿
        combined = np.vstack([vis_frame, panel])
        
        # ä¿å­˜å›¾åƒ
        filename = f"frame_{frame_idx:06d}_scores.jpg"
        filepath = os.path.join(self.clip_dir, filename)
        cv2.imwrite(filepath, combined)
    
    def log_vlm_verification(self, event_name: str, frames: List[np.ndarray],
                           is_confirmed: bool, reason: str, start_time: float):
        """è®°å½•VLMéªŒè¯ç»“æœ"""
        if not self.enabled or not self.save_vlm:
            return
        
        # åˆ›å»ºäº‹ä»¶ç›®å½•
        timestamp = datetime.now().strftime("%H%M%S_%f")[:12]
        event_dir = os.path.join(self.vlm_dir, f"{event_name}_{timestamp}")
        os.makedirs(event_dir, exist_ok=True)
        
        # ä¿å­˜è¾“å…¥å¸§
        for i, frame in enumerate(frames):
            filename = f"input_frame_{i+1}.jpg"
            filepath = os.path.join(event_dir, filename)
            cv2.imwrite(filepath, frame)
        
        # åˆ›å»ºæ‹¼æ¥å›¾ï¼ˆæ˜¾ç¤ºæ‰€æœ‰è¾“å…¥å¸§ï¼‰
        if len(frames) > 0:
            # è°ƒæ•´å¸§å¤§å°
            target_height = 240
            resized_frames = []
            for frame in frames:
                h, w = frame.shape[:2]
                target_width = int(w * target_height / h)
                resized = cv2.resize(frame, (target_width, target_height))
                resized_frames.append(resized)
            
            # æ°´å¹³æ‹¼æ¥
            if len(resized_frames) <= 4:
                combined = np.hstack(resized_frames)
            else:
                # åˆ†ä¸¤è¡Œ
                row1 = np.hstack(resized_frames[:4])
                row2 = np.hstack(resized_frames[4:])
                # è¡¥é½å®½åº¦
                if row2.shape[1] < row1.shape[1]:
                    pad_width = row1.shape[1] - row2.shape[1]
                    padding = np.zeros((row2.shape[0], pad_width, 3), dtype=np.uint8)
                    row2 = np.hstack([row2, padding])
                combined = np.vstack([row1, row2])
            
            # æ·»åŠ ç»“æœæ ‡ç­¾
            result_color = (0, 255, 0) if is_confirmed else (0, 0, 255)
            result_text = "CONFIRMED" if is_confirmed else "REJECTED"
            
            label_height = 60
            label_panel = np.zeros((label_height, combined.shape[1], 3), dtype=np.uint8)
            label_panel[:] = result_color
            
            cv2.putText(label_panel, f"VLM Result: {result_text}", 
                       (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
            
            combined_with_label = np.vstack([label_panel, combined])
            
            # ä¿å­˜æ‹¼æ¥å›¾
            combined_filename = f"vlm_result_{'confirmed' if is_confirmed else 'rejected'}.jpg"
            combined_filepath = os.path.join(event_dir, combined_filename)
            cv2.imwrite(combined_filepath, combined_with_label)
        
        # ä¿å­˜VLMç»“æœJSON
        result_data = {
            'event_name': event_name,
            'start_time': start_time,
            'timestamp': datetime.now().isoformat(),
            'is_confirmed': is_confirmed,
            'reason': reason,
            'num_frames': len(frames)
        }
        
        json_filepath = os.path.join(event_dir, 'vlm_result.json')
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, indent=2, ensure_ascii=False)
    
    def generate_summary(self):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        if not self.enabled:
            return
        
        print("ğŸ“Š Generating summary report...")
        
        # ç”ŸæˆCLIPå¾—åˆ†ç»Ÿè®¡
        if self.save_clip and self.clip_scores_data:
            self._generate_clip_summary()
        
        # ç”Ÿæˆæ€»è§ˆæ–‡æ¡£
        self._generate_overview()
        
        print(f"âœ… Summary saved to {self.summary_dir}")
    
    def _generate_clip_summary(self):
        """ç”ŸæˆCLIPå¾—åˆ†ç»Ÿè®¡"""
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        
        # æå–æ•°æ®
        frame_times = [d['frame_time'] for d in self.clip_scores_data]
        
        # è·å–æ‰€æœ‰äº‹ä»¶åç§°
        event_names = [k for k in self.clip_scores_data[0].keys() 
                      if k not in ['frame_idx', 'frame_time', 'num_detections']]
        
        # ç»˜åˆ¶å¾—åˆ†æ›²çº¿
        plt.figure(figsize=(14, 8))
        
        for event_name in event_names:
            scores = [d.get(event_name, 0) for d in self.clip_scores_data]
            plt.plot(frame_times, scores, label=event_name, linewidth=2)
        
        plt.xlabel('Time (seconds)', fontsize=12)
        plt.ylabel('CLIP Similarity Score', fontsize=12)
        plt.title('CLIP Similarity Scores Over Time', fontsize=14, fontweight='bold')
        plt.legend(loc='best', fontsize=10)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        plot_path = os.path.join(self.summary_dir, 'clip_scores_timeline.png')
        plt.savefig(plot_path, dpi=150)
        plt.close()
    def log_event_crop(self, crop_img: np.ndarray, event_name: str, score: float, frame_idx: int):
        """è®°å½•é€ç»™ CLIP çš„è£å‰ªå›¾"""
        if not self.enabled or not self.save_clip:
            return

        # åˆ›å»ºä¸“é—¨å­˜æ”¾è£å‰ªå›¾çš„æ–‡ä»¶å¤¹
        crop_dir = os.path.join(self.session_dir, '4_clip_crops', event_name)
        os.makedirs(crop_dir, exist_ok=True)
        
        # æ–‡ä»¶åå¸¦ä¸Šåˆ†æ•°ï¼Œæ–¹ä¾¿åˆ†æ
        filename = f"frame_{frame_idx:06d}_score_{score:.3f}.jpg"
        filepath = os.path.join(crop_dir, filename)
        
        # è¿™é‡Œçš„ crop_img æ˜¯ BGR æ ¼å¼çš„ (å› ä¸ºæ˜¯åœ¨è½¬ RGB ä¹‹å‰ä¼ è¿›æ¥çš„)ï¼Œå¯ä»¥ç›´æ¥ä¿å­˜
        cv2.imwrite(filepath, crop_img)
    
    def _generate_overview(self):
        """ç”Ÿæˆæ€»è§ˆæ–‡æ¡£"""
        overview_path = os.path.join(self.summary_dir, 'README.md')
        
        with open(overview_path, 'w', encoding='utf-8') as f:
            f.write(f"# Event Detection Results\n\n")
            f.write(f"**Session:** {os.path.basename(self.session_dir)}\n\n")
            f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write(f"## Directory Structure\n\n")
            f.write(f"```\n")
            f.write(f"{os.path.basename(self.session_dir)}/\n")
            f.write(f"â”œâ”€â”€ 1_yolo_detections/     # YOLOæ£€æµ‹ç»“æœï¼ˆå›¾åƒ+JSONï¼‰\n")
            f.write(f"â”œâ”€â”€ 2_clip_scores/         # CLIPç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆå›¾åƒ+CSVï¼‰\n")
            f.write(f"â”œâ”€â”€ 3_vlm_verifications/   # VLMéªŒè¯ç»“æœï¼ˆæŒ‰äº‹ä»¶åˆ†ç»„ï¼‰\n")
            f.write(f"â””â”€â”€ summary/               # æ±‡æ€»æŠ¥å‘Šå’Œç»Ÿè®¡å›¾è¡¨\n")
            f.write(f"```\n\n")
            
            f.write(f"## Statistics\n\n")
            f.write(f"- **YOLO Detections Saved:** {self.yolo_frame_count // self.yolo_sample_rate}\n")
            f.write(f"- **CLIP Scores Recorded:** {len(self.clip_scores_data)}\n")
            
            # VLMéªŒè¯ç»Ÿè®¡
            if os.path.exists(self.vlm_dir):
                vlm_subdirs = [d for d in os.listdir(self.vlm_dir) 
                              if os.path.isdir(os.path.join(self.vlm_dir, d))]
                confirmed = sum(1 for d in vlm_subdirs if 'confirmed' in d.lower())
                rejected = len(vlm_subdirs) - confirmed
                
                f.write(f"- **VLM Verifications:** {len(vlm_subdirs)} total\n")
                f.write(f"  - Confirmed: {confirmed}\n")
                f.write(f"  - Rejected: {rejected}\n")
            
            f.write(f"\n## How to Use\n\n")
            f.write(f"1. **YOLO Detections**: Check `1_yolo_detections/` for object detection results\n")
            f.write(f"2. **CLIP Scores**: View `2_clip_scores/clip_scores.csv` for detailed scores\n")
            f.write(f"3. **VLM Results**: Browse `3_vlm_verifications/` to see event verification results\n")
            f.write(f"4. **Summary**: Check `summary/clip_scores_timeline.png` for score trends\n")
    
    def _get_class_color(self, class_name: str) -> tuple:
        """è·å–ç±»åˆ«å¯¹åº”çš„é¢œè‰²"""
        colors = {
            'person': (255, 0, 0),
            'cat': (0, 255, 255),
            'dog': (255, 255, 0),
            'door': (0, 255, 0),
            'dining table': (255, 0, 255),
            'food': (0, 165, 255),
        }
        return colors.get(class_name, (200, 200, 200))
    
    def close(self):
        """å…³é—­æ—¥å¿—è®°å½•å™¨"""
        if not self.enabled:
            return
        
        # å…³é—­CSVæ–‡ä»¶
        if hasattr(self, 'clip_csv_file'):
            self.clip_csv_file.close()
        
        # ç”Ÿæˆæ±‡æ€»
        self.generate_summary()